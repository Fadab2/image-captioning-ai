# ğŸ–¼ï¸ Image Captioning AI App with BLIP and Gradio

This is a simple yet powerful image captioning web application built with Python, [BLIP](https://huggingface.co/Salesforce/blip-image-captioning-base), and [Gradio](https://gradio.app/). It automatically generates descriptive captions for uploaded images using a pre-trained vision-language transformer model.

---

## ğŸš€ Demo

![demo](images/demo-screenshot.png) <!-- Optional: Add a screenshot here -->

Try it locally by uploading an image, and the app will instantly generate a caption!

---

## ğŸ§  How It Works

This app uses:

- **BLIP (Bootstrapping Language-Image Pretraining)** from Hugging Face for image captioning
- **Gradio** for a lightweight, interactive web UI
- **PIL (Pillow)** to handle image data
- **Transformers** for model access and inference

---

## ğŸ“¦ Features

- ğŸ§  Automatically generates human-readable image captions
- âš¡ Easy-to-use Gradio interface
- ğŸŒ Can be adapted to run in cloud, local, or integrated into web apps
- ğŸ“ Includes a version for scraping images from webpages using BeautifulSoup

---

## ğŸ“ Project Structure

```bash
/home/project/
â”‚
â”œâ”€â”€ image_cap.py                # Simple image captioning with BLIP
â”œâ”€â”€ image_captioning_app.py     # Gradio-powered web app
â”œâ”€â”€ automate_url_captioner.py   # Bonus: Auto-captioning from webpage images
â”œâ”€â”€ image1.jpg                  # Sample image
â”œâ”€â”€ my_env/                     # Virtual environment (not tracked)
â”œâ”€â”€ captions.txt                # Output from URL captioning script
â””â”€â”€ README.md
